<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Microsoft Foundry on Innovation with tech</title>
    <link>https://beanhsiang.github.io/categories/Microsoft-Foundry/</link>
    <description>Recent content in Microsoft Foundry on Innovation with tech</description>
    <generator>Hugo</generator>
    <language>zh-Hans</language>
    <lastBuildDate>Sun, 04 Jan 2026 12:00:00 +0800</lastBuildDate>
    <atom:link href="https://beanhsiang.github.io/categories/Microsoft-Foundry/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>为 Azure Voice Live 构建可用于生产的 SIP 网关</title>
      <link>https://beanhsiang.github.io/post/2026-01-04-building-a-production-ready-sip-gateway-for-azure-voice-live/</link>
      <pubDate>Sun, 04 Jan 2026 12:00:00 +0800</pubDate>
      <guid>https://beanhsiang.github.io/post/2026-01-04-building-a-production-ready-sip-gateway-for-azure-voice-live/</guid>
      <description>&lt;p&gt;原文链接：&lt;a href=&#34;https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/from-zero-to-hero-building-a-production-ready-sip-gateway-for-azure-voice-live/4473405?WT.mc_id=AI-MVP-5003172&#34;&gt;https://techcommunity.microsoft.com/blog/azure-ai-foundry-blog/from-zero-to-hero-building-a-production-ready-sip-gateway-for-azure-voice-live/4473405?WT.mc_id=AI-MVP-5003172&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&#xA;        &lt;a data-fancybox=&#34;gallery&#34; href=&#34;https://beanhsiang.github.io/uploads/20260105102739-236de1e20b0f4b64a8b41a799b4589a0.png&#34;&gt;&#xA;            &lt;img class=&#34;mx-auto&#34; alt=&#34;&#34; src=&#34;https://beanhsiang.github.io/uploads/20260105102739-236de1e20b0f4b64a8b41a799b4589a0.png&#34; /&gt;&#xA;        &lt;/a&gt;&#xA;    &lt;/p&gt;&#xA;&lt;p&gt;&lt;em&gt;题图来源：Microsoft Tech Community / Microsoft Foundry Blog&lt;/em&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;引言&#34;&gt;引言&lt;/h2&gt;&#xA;&lt;p&gt;语音技术正在重塑人和机器的交互方式，让与 AI 的对话比以往更自然。随着 Voice Live API 的 public beta 发布，开发者拥有了构建低延迟、多模态语音体验的工具，在应用中可以做出很多新玩法。&lt;/p&gt;&#xA;&lt;p&gt;过去，想做一个语音机器人，往往需要把多个模型“串起来”：比如用 ASR（自动语音识别）模型（像 Whisper）做转写、再用文本模型做推理、最后用 TTS（文本转语音）模型生成语音输出。这条链路通常会带来明显延迟，并且在情感表达等细节上会有损失。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
